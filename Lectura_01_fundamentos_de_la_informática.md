### Lectura 1. **Breve Esbozo de la Computación**

#### 1. **Introducción**

La *informática* es una de las disciplinas que más ha transformado el mundo moderno. Sus raíces están profundamente ligadas a las *ciencias de la computación* ("*computer science*"), que son el corazón de la tecnología contemporánea y tienen aplicaciones en todos los campos imaginables: desde la salud y la educación hasta la administración de negocios y las finanzas. Sin embargo, aunque comúnmente se asocian con el simple uso de computadoras, las ciencias de la computación abarcan mucho más. Involucran el estudio de sistemas, algoritmos, datos y los principios matemáticos que sustentan casi todas las tecnologías que usamos a diario.

Para los estudiantes de administración, comprender los principios de la informática no solo es importante, sino fundamental. ¿Por qué? Porque en un mundo cada vez más digital, la capacidad para manejar grandes cantidades de información de manera eficiente, tomar decisiones informadas y optimizar procesos es crucial para el éxito en el ámbito profesional. En palabras de Denning (1985), las ciencias de la computación son *“el cuerpo de conocimiento que trata sobre el diseño, análisis, implementación y aplicación de procesos que transforman información”* (p. 16). 

Sin embargo, es importante aclarar la diferencia entre *informática* y *ciencias de la computación*. Las ciencias de la computación se enfocan en la creación de las bases teóricas y técnicas de la computación, mientras que la *informática* es la aplicación de esos conocimientos a áreas específicas como la administración, la biomedicina o la educación. A lo largo de esta lectura, exploraremos los orígenes de la computación, desde las primeras calculadoras mecánicas hasta las modernas computadoras digitales, y veremos cómo las ciencias de la computación han moldeado el mundo que conocemos hoy.

#### 2. **Antecedentes de la Computación**

La historia de la computación se remonta a la antigüedad, cuando la humanidad comenzó a desarrollar herramientas para el cálculo. Uno de los primeros dispositivos fue el ábaco, utilizado en la antigua Mesopotamia hace más de 4,000 años. Los sistemas numéricos avanzaron aún más con los mayas y otras civilizaciones, pero fue en el siglo XIX cuando la computación dio un salto cualitativo con la invención de la *máquina diferencial* de Charles Babbage. Esta máquina, diseñada para automatizar los cálculos matemáticos, es considerada uno de los primeros precursores de las computadoras modernas.

Sin embargo, el verdadero punto de inflexión en la historia de la computación llegó en 1936, cuando Alan Turing publicó su trabajo "On Computable Numbers". En este documento, Turing propuso la idea de una máquina teórica que podía realizar cualquier cálculo que fuera computable. Esta máquina, conocida como la *máquina de Turing*, podía resolver cualquier problema matemático que pudiera describirse mediante un conjunto finito de reglas. Este concepto sentó las bases de lo que hoy conocemos como computadoras digitales. Como afirmó Turing, “cualquier problema que pueda ser resuelto por un humano siguiendo un conjunto de instrucciones también puede ser resuelto por una máquina” (Turing, 1936).

Unos años más tarde, en 1945, otro pionero de la computación, *John von Neumann*, propuso lo que hoy conocemos como la *arquitectura de von Neumann*. Este modelo sugería que las computadoras podían almacenar tanto los datos como los programas en una misma memoria, lo que permitiría ejecutar múltiples tareas de manera eficiente y flexible (von Neumann, 1945). Este concepto sigue siendo el estándar en las computadoras modernas y ha permitido el desarrollo de sistemas más complejos y potentes.

#### 3. **La computadora: antes humana hoy casi huamana**

Antes de la aparición de las computadoras electrónicas, los cálculos complejos eran realizados por personas, muchas de ellas mujeres, conocidas como *calculistas humanas* o "*human computers*". Durante la Segunda Guerra Mundial, estas calculistas jugaron un papel crucial en la elaboración de tablas matemáticas para propósitos militares, pero el trabajo manual tenía sus limitaciones: era lento, propenso a errores y, en muchos casos, simplemente insuficiente para satisfacer las crecientes demandas.

Es aquí donde entra en juego la *ENIAC (Electronic Numerical Integrator and Computer)*, la primera computadora electrónica de propósito general, construida en 1945. La ENIAC fue diseñada para calcular trayectorias balísticas para el ejército de Estados Unidos, pero su capacidad para realizar cálculos a velocidades sin precedentes la convirtió rápidamente en un hito de la ingeniería. Según Goldstine y Goldstine (1946), "con la introducción del ENIAC, los cálculos que antes tomaban meses podían ahora completarse en cuestión de minutos" (p. 8). Este avance no solo revolucionó el campo militar, sino que también inició la transición hacia una nueva forma de interactuar con los números y la información, sentando las bases para el desarrollo de la informática moderna.

La llegada de la ENIAC marcó el inicio de la era de las computadoras electrónicas. Además, el 15 de septiembre de 1947 se fundó la *Association for Computing Machinery (ACM)*, la primera sociedad científica y educativa dedicada exclusivamente a la computación. Unos años después, en 1958, se reconocieron formalmente las *ciencias de la computación* como un campo de estudio autónomo, un momento crucial en la historia de la tecnología. Entonces se acuñaron los primeros términos como "*bit*" (abreviatura de *binary digit*), "*hardware*" y "*software*", que hoy son fundamentales para entender la computación. Hoy, el poder de la computadora está al alcance de todos en un teléfono celular con *inteligencia artificial* integrada. 

#### 4. **Las Ciencias de la Computación**

Las ciencias de la computación son una disciplina que combina teoría, matemáticas, lógica y tecnología. Dentro de sus áreas más importantes encontramos los *algoritmos*, que son secuencias de instrucciones paso a paso para resolver problemas específicos; las *estructuras de datos*, que permiten organizar y almacenar información de manera eficiente y los *lenguajes de programación*, que son las herramientas que utilizamos para darle instrucciones a las computadoras; y los *sistemas operativos* como windows o Android, que gestionan los recursos del hardware y permiten que los programas funcionen correctamente. En ese poder de cómputo radica la importancia de *aprender a programar*.

En otro ensayo mencione que "las ciencias de la computación nunca han sido una disciplina en el sentido tradicional, sino más bien un paraguas interdisciplinario que reúne métodos y teorías de diversas áreas" (Zavala, 2011, p. 56). Esta característica transdisciplinaria ha permitido que las ciencias de la computación influyan en todos los campos del conocimiento. Hoy en día, las ciencias de la computación no solo se aplican en la ingeniería o la ciencia, sino también en áreas tan diversas como la medicina, la biología, la geografía, las ciencias sociales, las humanidades, las artes y, por supuesto, la administración. 

Uno de los avances más importantes en la historia de las ciencias de la computación ha sido el desarrollo de *algoritmos* que permiten a las computadoras procesar *datos* de manera eficiente. Un algoritmo es, en esencia, una receta que, cuando se sigue correctamente, resuelve un problema de manera sistemática. El 17 de noviembre de 1951, con el *Proyecto LEO*, en Gran Bretaña, se ejecutó el primer programa de software del mundo para administrar un negocio  (Zavala, 2011, p. 80), sentando las bases para la informática tal como la conocemos hoy. Estos algoritmos son la base de los sofisticados sistemas de gestión empresarial como los sistemas *ERP* (Enterprise Resource Planning) y *CRM* (Customer Relationship Management). 

#### 5. **Conclusión**

Como hemos visto, los fundamentos de la informática son mucho más que un conjunto de conceptos técnicos, pues son la base sobre la cual se construye gran parte de la tecnología que utilizamos en nuestra vida diaria. Desde los primeros cálculos manuales hasta las avanzadas computadoras electrónicas de hoy en día, la computación ha transformado radicalmente nuestra forma de trabajar, pensar y tomar decisiones. En el ámbito administrativo, el dominio de estos conceptos es crucial, ya que permite optimizar procesos, gestionar datos con mayor eficiencia y tomar decisiones más informadas.

El desafío de este curso es que, al finalizar, ustedes sean capaces no solo para entender el hardware y el software que componen su computadora y su teléfono, sino que también puedan aplicar estos conocimientos en la resolución de problemas reales en el campo de la administración. Como dijo Denning (1985), “la computación es la disciplina que da forma al futuro, transformando la información en conocimiento y el conocimiento en acción” (p. 16). La informática no es solo una herramienta, sino una puerta abierta a innumerables posibilidades para quienes la dominen. ¡Bienvenidos a este fascinante campo!

---

### Referencias

- Denning, P. J. (1985). What is Computer Science? *American Scientist*, *73*(1), 16-19.
- Goldstine, H. H., & Goldstine, A. (1946). *The Electronic Numerical Integrator and Computer (ENIAC)*. Report.
- Turing, A. (1936). On computable numbers, with an application to the Entscheidungsproblem. *Proceedings of the London Mathematical Society*.
- von Neumann, J. (1945). *First Draft of a Report on the EDVAC*.
- Zavala, J. (2011). ¿Qué son las ciencias de la computación?. *In* *La ingeniería de software: Una discusión epistemológica*. Tesis. México: Universidad Autónoma Metropolitana.
