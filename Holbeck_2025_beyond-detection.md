### **Más allá de la detección: Por qué los docentes deberían centrarse en la alfabetización en IA, no en la vigilancia de la IA**[^1]  

*Por Rick Holbeck / Mayo 2025*  

Tipo: Opinión, Tecnologías Emergentes, Educación Superior, Desarrollo Profesional  

El auge de la inteligencia artificial generativa (GenAI) ha transformado el panorama educativo. Los estudiantes ahora tienen acceso a herramientas poderosas que pueden generar ensayos, responder preguntas y simular procesos de pensamiento. Si bien estas herramientas ofrecen oportunidades emocionantes para mejorar el aprendizaje, también plantean preocupaciones importantes relacionadas con el plagio, la dependencia excesiva y la erosión de la integridad académica [1, 2]. Como resultado, las instituciones luchan por determinar cómo responder mejor.  

Muchas universidades han optado por software de detección de IA como mecanismo principal de control. Sin embargo, estas herramientas de detección tienen limitaciones y a menudo se aplican en contextos punitivos. Pueden fomentar dinámicas adversas entre estudiantes y docentes, especialmente cuando se acusa falsamente a los estudiantes [1]. La detección por sí sola no fomenta un compromiso ético con la tecnología ni prepara a los estudiantes para el mundo complejo donde la GenAI será la norma.  

En lugar de plantear la alfabetización en IA y la vigilancia de la IA como paradigmas opuestos, investigaciones recientes destacan el valor de un marco equilibrado e integrado [3, 4, 5]. Este artículo argumenta que combinar políticas claras de uso de IA con esfuerzos educativos proactivos ayudará a los estudiantes a convertirse en usuarios informados y éticos de las tecnologías de IA, tanto en contextos académicos como laborales.  

#### Las limitaciones de las herramientas de detección de IA  

Las herramientas de detección de IA operan analizando patrones lingüísticos, probabilidades y otras características para evaluar si el contenido es probablemente generado por IA. Sin embargo, estas herramientas no son consistentemente precisas. Las investigaciones muestran que frecuentemente clasifican erróneamente trabajos escritos por humanos como generados por IA y, a veces, no detectan contenido escrito por IA en absoluto [1].  

Estos falsos positivos pueden tener consecuencias graves para los estudiantes. Un trabajo mal identificado puede llevar a sanciones, probation académico o incluso expulsión si las instituciones no verifican los resultados adecuadamente. Además, el costo emocional de ser acusado falsamente de deshonestidad puede ser sustancial.  

Weber-Wulff et al. enfatizan que la dependencia excesiva de estas herramientas desplaza el enfoque institucional del aprendizaje a la vigilancia [1]. Los estudiantes pueden preocuparse más por evitar la detección que por desarrollar sus habilidades analíticas o de razonamiento ético. Las instituciones deben alejarse de un modelo puramente reactivo y adoptar un enfoque más solidario y centrado en la educación.  

#### Integración de la alfabetización en IA y la política institucional  

La alfabetización en IA se define como la capacidad de comprender cómo funcionan los sistemas de IA, evaluar críticamente sus resultados y usarlos éticamente [6]. Sin embargo, como argumenta Chan, la alfabetización debe integrarse en un marco institucional más amplio que incluya políticas claras y bien comunicadas sobre el uso de IA [4]. La política sin alfabetización resulta en aplicación sin comprensión; la alfabetización sin política genera confusión e inconsistencia.  

Cordero et al. enfatizan que los modelos institucionales más efectivos combinan educación en ética de IA con pautas de uso transparentes [3]. En su estudio de mejores prácticas en educación superior, los investigadores encontraron que las políticas alineadas con estrategias educativas generaron mayores niveles de participación estudiantil y mejores resultados de aprendizaje. Las políticas deben definir claramente casos de uso aceptables para la IA (ya sea para lluvia de ideas, resúmenes o corrección gramatical) y explicar las consecuencias del mal uso. Cuando docentes y estudiantes se alinean mediante política y pedagogía, el resultado es una cultura de confianza e innovación. Este enfoque dual permite a los estudiantes explorar el potencial de la IA dentro de límites claramente definidos.  

### Estrategias para fomentar la alfabetización en IA  

La alfabetización en IA se refiere a la capacidad de comprender, evaluar críticamente y utilizar eficazmente herramientas de IA de manera ética e informada [6]. En lugar de penalizar a los estudiantes por interactuar con la IA, los docentes deberían integrar la alfabetización en IA en sus planes de estudio enseñando a evaluar el contenido generado por IA en cuanto a precisión, sesgos e implicaciones éticas. Desarrollar estas competencias permite a los estudiantes usar la IA como herramienta para mejorar el aprendizaje, no como atajo para eludir el esfuerzo intelectual.  

Para cultivar la alfabetización en IA, las instituciones deberían considerar cuatro estrategias prácticas y escalables, basadas en investigaciones y casos de estudio actuales:  

1. **Pautas transparentes de uso de IA**:  
   La claridad es esencial al introducir políticas relacionadas con la IA. Los docentes deben explicar explícitamente qué constituye un uso aceptable e inaceptable de la IA, ofreciendo ejemplos y fundamentos. Las políticas claras reducen la confusión y refuerzan la toma de decisiones éticas.  
   *Kasneci et al. reportan que los estudiantes siguen más las pautas cuando se explican a fondo en lugar de imponerse [5]. Chan recomienda un enfoque escalonado donde adaptaciones departamentales apoyen las normas institucionales [4].*  

2. **Ejercicios de pensamiento crítico asistidos por IA**:  
   En lugar de prohibir las herramientas de IA, los educadores pueden usarlas para mejorar habilidades de pensamiento crítico. Un método efectivo es asignar la generación de respuestas mediante IA y luego su crítica. Esto fomenta habilidades analíticas y enseña a cuestionar información.  
   *Smolansky et al. descubrieron que estas tareas mejoraron el pensamiento evaluativo y la confianza académica [2]. Al posicionar la IA como "socio cognitivo", se redefine el enfoque del aprendizaje.*  

3. **Tareas sobre ética de IA**:  
   La ética debe ser central en la educación sobre IA. Tareas que invitan a reflexionar sobre implicaciones como sesgos algorítmicos o desinformación fomentan responsabilidad cívica.  
   *Cordero et al. destacan integrar debates éticos en contextos disciplinares [3]. Estas reflexiones pueden adoptar múltiples formatos (estudios de caso, debates), haciendo la ética tangible.*  

4. **Exploración colaborativa de IA**:  
   Actividades grupales con IA fomentan aprendizaje colaborativo. La discusión proporciona perspectivas múltiples sobre su rol en el aprendizaje.  
   *Tzirides et al. comprobaron que esto aumenta la confianza y normaliza el uso académico de la IA [7]. La reflexión estructurada post-actividad consolida aprendizajes.*  

#### Cambio de mentalidad docente mediante desarrollo profesional  

Si bien la preparación estudiantil es esencial, las actitudes docentes moldean cómo se percibe y usa la IA. Muchos educadores temen que la GenAI reduzca estándares académicos o fomente el plagio [8].  

*Palmer et al. descubrieron que estos temores suelen basarse en suposiciones [9]. Los docentes sobrestiman el mal uso estudiantil y subestiman el potencial pedagógico de la IA. Para abordarlo, se requiere desarrollo profesional con:  
- Sesiones prácticas donde los docentes experimenten con herramientas de IA [8]  
- Demostraciones y estudios de caso  
- Ejercicios de resolución de problemas en grupos pequeños*  

#### Futuras direcciones de investigación  

La alfabetización en IA en educación es un campo emergente que requiere más estudio:  
- **Investigaciones longitudinales** sobre impacto en conciencia ética  
- **Comparaciones interinstitucionales** de modelos de implementación  
- **Enfoque en equidad**: Acceso a IA en poblaciones desfavorecidas  
- Desarrollo de **estándares globales** para integración ética  

#### Conclusión  

La GenAI transforma cómo aprendemos, enseñamos y evaluamos. Si bien las herramientas de detección pueden señalar malos usos, no deben ser la respuesta central institucional. El énfasis excesivo en la vigilancia socava la confianza y no prepara para entornos laborales con IA.  

Las instituciones deben invertir en:  
1. Integración curricular de alfabetización en IA  
2. Políticas transparentes  
3. Desarrollo profesional docente  

Este enfoque holístico permite a los estudiantes explorar, cuestionar y usar la IA éticamente. Prepararlos para un mundo impulsado por IA exige más que prevenir malos usos: requiere enseñarles a usar estas herramientas con sabiduría, ética y comprensión profunda de su poder. La educación superior está singularmente posicionada para liderar este cambio.  

#### Referencias  

[1] Weber-Wulff, D. et al. [Testing detection tools for AI-generated text](https://doi.org/10.1007/s40979-023-00146-z). *International Journal for Educational Integrity* 19, 1 (2023), 1–20.

[2] Cotton, D. R. E., Cotton, P. A., and Shipway, J. R. [Chatting and cheating: Ensuring academic integrity in the era of ChatGPT](https://doi.org/10.1080/14703297.2023.2190148). *Innovations in Education and Teaching International* 61, 2 (2024), 228–239.

[3] Cordero, J., Torres-Zambrano, J., and Cordero-Castillo, A. [Integration of generative artificial intelligence in higher education: Best practices](https://doi.org/10.3390/educsci15010032). *Education Sciences* 15, 1 (2024), Article 32.

[4] Chan, C. [A comprehensive AI policy education framework for university teaching and learning](https://doi.org/10.1186/s41239-023-00408-3). *International Journal of Educational Technology in Higher Education* 20, 1 (2023), Article 56.

[5] Kasneci, E., et al. [ChatGPT for good? Opportunities and challenges of large language models for education](https://doi.org/10.1016/j.lindif.2023.102274). *Learning and Individual Differences* 103 (2023), Article 102274.

[6] Zhai, X. [ChatGPT for education: A pedagogical discussion](https://doi.org/10.3389/fpsyg.2024.1458551). *Frontiers in Psychology* 14 (2023), Article 1130085.

[7] Tzirides, A. et al. [Combining human and artificial intelligence for enhanced AI literacy in higher education](https://doi.org/10.1016/j.caeo.2024.100184). *Computers and Education Open* 5 (2024), Article 100024.

[8] Mollick, E. and Mollick, L. [Assigning AI: Seven approaches for students with AI tools like ChatGPT](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4475995). The Wharton School Research Paper. September 23, 2023.

[9] Palmer, E. et al. [Findings from a survey looking at attitudes towards AI and its use in teaching, learning and research](https://doi.org/10.14742/apubs.2023.537). *ASCILITE Publications* (2023), 212–223.

### Sobre el autor  

Rick Holbeck, M.Ed., M.S. es director ejecutivo de instrucción en línea en Grand Canyon University. Su investigación se centra en aprendizaje en línea, compromiso estudiantil y tecnología educativa. Actualmente explora usos de IA para apoyar la enseñanza. Es investigador y ponente activo en educación digital.  

---  
[^1]: Fuente: Holbeck, R. (2025, May). Beyond detection: Why faculty should focus on AI literacy, not AI policing. *eLearn Magazine*, *2025*(5: Article No.: 3) DOI: [10.1145%2F3735548.3729174](https://doi.org/10.1145/3735548.3729174) 
